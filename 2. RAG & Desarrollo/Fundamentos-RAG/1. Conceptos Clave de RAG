# Conceptos Clave de RAG ‚Äì Parte 2: RAG con Azure AI Search üß†

## 1. ¬øPor qu√© usar Azure AI Search en RAG?

Azure AI Search (antes Cognitive Search) es el motor recomendado por Microsoft para construir soluciones RAG seguras y escalables. Proporciona:

- Indexaci√≥n eficiente de contenido heterog√©neo (PDF, bases de datos, im√°genes, etc.)  
- B√∫squeda vectorial, full-text y h√≠brida  
- Seguridad empresarial, control de acceso y cumplimiento normativo  
- Integraci√≥n nativa con Azure OpenAI y Azure AI Foundry :contentReference[oaicite:1]{index=1}  

### Ventajas clave

- Permite indexar datos a escala y refrescarlos peri√≥dicamente :contentReference[oaicite:2]{index=2}  
- Asegura que los resultados sean relevantes y aptos para LLMs :contentReference[oaicite:3]{index=3}  

---

## 2. Arquitectura RAG con Azure AI Search

1. **App de usuario** (web o chat) env√≠a consulta.  
2. **Azure AI Search** busca y recupera fragmentos relevantes.  
3. La consulta + resultados se env√≠an a un **LLM** (ej. GPT‚Äë4) que genera la respuesta.  
4. Puede haber pasos adicionales como reconsulta si la primera respuesta no es satisfactoria :contentReference[oaicite:4]{index=4}.

El motor de b√∫squeda no genera texto, solo entrega datos para el LLM :contentReference[oaicite:5]{index=5}.

---

## 3. Creaci√≥n de √≠ndices en Azure AI Foundry

Desde el portal de Azure AI Foundry:

1. Ve a **Knowledge ‚Üí Vector Indexes**  
2. Elige **Azure AI Search** como backend  
3. Define:
   - Nombre del √≠ndice (ej. `rag_business_index`)
   - Fuente de datos (Blob, SQL, BLOB)
   - Embedding model (ej. `text-embedding-ada-002`) :contentReference[oaicite:6]{index=6}  
4. Crea el √≠ndice; este realiza chunking y vectorizaci√≥n autom√°ticamente :contentReference[oaicite:7]{index=7}  

---

## 4. Tipos de b√∫squeda

- **Vector search**: encuentra fragmentos sem√°nticamente similares :contentReference[oaicite:8]{index=8}  
- **Full‚Äëtext search**: √∫til para coincidencias exactas y filtros :contentReference[oaicite:9]{index=9}  
- **Hybrid search**: combina ambos m√©todos en una √∫nica consulta (vector + texto) :contentReference[oaicite:10]{index=10}  
- **Semantic ranking**: reordena resultados usando modelos ML para priorizar relevancia sem√°ntica :contentReference[oaicite:11]{index=11}  

---

## 5. Integraci√≥n LLM ‚Äì b√∫squeda ‚Äì respuesta

- El usuario pregunta; Azure AI Search devuelve fragmentos (hasta k resultados)  
- Se arma un prompt al LLM que incluye:
  - Pregunta original  
  - Fragmentos de contexto  
  - Indicaciones como ‚Äúsolo responde con lo que est√© en los fragmentos‚Äù  
- LLM genera respuesta basada en contexto externo, minimizando alucinaciones :contentReference[oaicite:12]{index=12}  

Azure OpenAI y Azure AI Search pueden integrarse directamente con una sola API ‚Äì ‚ÄúOpenAI on your data‚Äù :contentReference[oaicite:13]{index=13}.

---

## 6. Embedding y chat models

- **Embedding models**: usados tanto al indexar documentos como al convertir consultas en vectores. Es crucial usar el mismo modelo en ambos extremos (por ej. `text‚Äëembedding‚Äëada‚Äë002`) :contentReference[oaicite:14]{index=14}  
- **Chat models**: LLMs que generan respuestas (GPT‚Äë4, GPT‚Äë3.5, GPT‚Äë4o), desplegables desde Azure OpenAI o Foundry :contentReference[oaicite:15]{index=15}

---

## 7. Seguridad y control

- Control de acceso (RBAC) para √≠ndices y b√∫squeda :contentReference[oaicite:16]{index=16}  
- En entornos regulados, puedes filtrar resultados por metadatos (fecha, planta, etc.) usando search filters :contentReference[oaicite:17]{index=17}  
- Garantiza compliance al mantener datos locales y seguros dentro de la nube

---

## 8. Beneficios y casos de uso

- **Inicio r√°pido** gracias al setup sin c√≥digo en portal  
- **Escalabilidad** y bajo mantenimiento al indexar contenido autom√°ticamente :contentReference[oaicite:18]{index=18}  
- **Flexibilidad** en fuentes de datos: Blob, SQL, SharePoint, etc. :contentReference[oaicite:19]{index=19}  
- **Casos t√≠picos**: atenci√≥n al cliente, soporte t√©cnico, documentos normativos, conocimientos internos

---

## 9. Referencias oficiales

- RAG en Azure AI Search ‚Äì visi√≥n general :contentReference[oaicite:20]{index=20}  
- Quickstart RAG con Azure AI Search y OpenAI :contentReference[oaicite:21]{index=21}  
- Vector indexes en Azure AI Foundry :contentReference[oaicite:22]{index=22}  
- Modelos de embeddings y chat para RAG :contentReference[oaicite:23]{index=23}  
- Beneficios de hybrid & semantic ranking :contentReference[oaicite:24]{index=24}  
